{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8691ff50bc38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpatsy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdmatrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutliers_influence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "#Import Necessary Library's\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import folium\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pathlib import Path\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up file path\n",
    "data_folder = Path(\"./Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HappinessFile = data_folder / \"2019 Happiness Data.csv\"\n",
    "\n",
    "#Import Data to Pandas DataFrame\n",
    "happinessDF = pd.read_csv(HappinessFile)\n",
    "happinessDF2 = happinessDF.drop(happinessDF.columns.difference([\"Country or region\", \"Score\"]), axis = 1)\n",
    "happinessDF2.rename(columns = {\"Score\": \"Happiness Score\", \"Country or region\": \"Country Name\"}, inplace = True)\n",
    "happinessDF2.set_index(\"Country Name\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "FreedomFile = data_folder / \"economic_freedom_index2019_data.csv\"\n",
    "\n",
    "#Import Data to Pandas DataFrame\n",
    "economicFreedomDF = pd.read_csv(FreedomFile,encoding='latin-1')\n",
    "economicFreedomDF = economicFreedomDF.dropna(subset=[\"World Rank\"])\n",
    "economicFreedomDF2 = economicFreedomDF.drop(economicFreedomDF.columns.difference([\"Country Name\",\"2019 Score\",\"Financial Freedom\", \"Population (Millions)\", \"Unemployment (%)\", \"Inflation (%)\"]), axis = 1)\n",
    "economicFreedomDF2.rename(columns = {\"2019 Score\": \"Economic Freedom\"}, inplace = True)\n",
    "economicFreedomDF2.set_index(\"Country Name\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "GDPData = data_folder / \"GDPfinal.json\"\n",
    "\n",
    "# read in json file of GDP data \n",
    "GDPDF = pd.read_json(GDPData)\n",
    "\n",
    "GDPDF2 = GDPDF.drop(GDPDF.columns.difference([\"Country\",\"Growth Rate\", \"GDP (IMF)\", \"GDP Per Capita\"]), 1)\n",
    "GDPDF2.drop(GDPDF2.index[GDPDF2[\"GDP (IMF)\"] == \"-\"], inplace=True)\n",
    "GDPDF2.dropna(subset=[\"Growth Rate\"], inplace = True)\n",
    "GDPDF2.rename(columns = {\"GDP (IMF)\": \"GDP (Billions)\", \"Country\": \"Country Name\"}, inplace = True)\n",
    "GDPDF2.set_index(\"Country Name\", inplace = True)\n",
    "\n",
    "for rowlabel, rowseries in GDPDF2.iterrows():\n",
    "    GDPDF2.loc[rowlabel, \"GDP Per Capita\"] = float(re.sub(\"[^0-9.]\", \"\", GDPDF2.loc[rowlabel, \"GDP Per Capita\"]))\n",
    "    GDPDF2.loc[rowlabel, \"Growth Rate\"] = float(re.sub(\"[^0-9.]\", \"\", GDPDF2.loc[rowlabel, \"Growth Rate\"]))\n",
    "    \n",
    "    gdp = GDPDF2.loc[rowlabel, \"GDP (Billions)\"]\n",
    "    gdpMag = gdp[-2:]\n",
    "    gdpClean = float(re.sub(\"[^0-9.]\", \"\", gdp))\n",
    "    \n",
    "    if gdpMag == \"Tn\":\n",
    "        GDPDF2.loc[rowlabel, \"GDP (Billions)\"] = gdpClean * 1000\n",
    "    elif gdpMag == \"Bn\":\n",
    "        GDPDF2.loc[rowlabel, \"GDP (Billions)\"] = gdpClean\n",
    "    elif gdpMag == \"Mn\":\n",
    "        GDPDF2.loc[rowlabel, \"GDP (Billions)\"] = gdpClean/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = happinessDF2.join(economicFreedomDF2, on = 'Country Name', how = \"inner\")\n",
    "df_final = df.join(GDPDF2, on = 'Country Name', how = \"inner\")\n",
    "df_final = df_final.astype(float)\n",
    "corrMatrix = df_final.corr(method = \"pearson\")\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of our analysis is to see whether we're able to predict Happiness Score by some economic factors. The above correlation matrix can help us perform some exploratory data analysis. By looking at the top row, we can see which variables are most correlated with Happiness Score, our response. The variables that look most important seem to be GDP, economic freedom, financial freedom, and GDP per capita. We can also look to see if there is any early indication of multicollinearity if we were to want to try and fit a multiple linear regression with multiple predictors. We're looking for correlation between predictors of greater than or equal to 0.8. We'll verify this in greater detail later in the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can begin our analysis by fitting a simple linear regression on each of the predictors that we saw could be good at predicting happiness score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(df_final[\"Economic Freedom\"],df_final[\"Happiness Score\"], \"bo\")\n",
    "pyplot.xlabel(\"Economic Freedom\")\n",
    "pyplot.ylabel(\"Happiness Score\")\n",
    "pyplot.title(\"Economic Freedom vs Happiness Score\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatterplot looks linear so we can fit a linear model to the data and no transformation is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_final[\"Economic Freedom\"]\n",
    "y = df_final[\"Happiness Score\"]\n",
    "\n",
    "A = np.vstack([x, np.ones(len(x))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, SSE = np.linalg.lstsq(A, y, rcond=None)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pyplot.plot(x, y, 'o', label='Original data')\n",
    "_ = pyplot.plot(x, model[0]*x + model[1], 'r', label='Fitted line')\n",
    "_ = pyplot.xlabel(\"Economic Freedom\")\n",
    "_ = pyplot.ylabel(\"Happiness Score\")\n",
    "_ = pyplot.title(\"Economic Freedom vs Happiness Score\")\n",
    "_ = pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find R^2 of model\n",
    "rSquare2 = 1 - SSE[0] / sum((y - y.mean())**2) \n",
    "rSquare2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 of this model is 0.4523. This tells us that 45.23% of the variation in happiness score can be explained by economic freedom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Model\n",
    "pyplot.plot(df_final[\"GDP (Billions)\"],df_final[\"Happiness Score\"], \"bo\") #Covers several orders of magnitude\n",
    "pyplot.xlabel(\"GDP (Billions)\")\n",
    "pyplot.ylabel(\"Happiness Score\")\n",
    "pyplot.title(\"GDP (Billions) vs Happiness Score\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second variable we wish to explore is GDP in billions of dollars. This scatterplot is not that great and differs from what we would expect by many orders of magnitude. We should take a log() transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform GDP Billions\n",
    "pyplot.plot(np.log(df_final[\"GDP (Billions)\"]),df_final[\"Happiness Score\"], \"bo\") #Covers several orders of magnitude\n",
    "pyplot.xlabel(\"GDP (Billions)\")\n",
    "pyplot.ylabel(\"Happiness Score\")\n",
    "pyplot.title(\"GDP (Billions) vs Happiness Score\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log() transformation fixes our scatterplot. We can now fit a linear model with log(GDP). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.log(df_final[\"GDP (Billions)\"])\n",
    "\n",
    "A2 = np.vstack([x2, np.ones(len(x2))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2, SSE2 = np.linalg.lstsq(A2, y, rcond=None)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pyplot.plot(x2, y, 'o', label='Original data')\n",
    "_ = pyplot.plot(x2, model2[0]*x2 + model2[1], 'r', label='Fitted line')\n",
    "_ = pyplot.xlabel(\"log(GDP (Billions))\")\n",
    "_ = pyplot.ylabel(\"Happiness Score\")\n",
    "_ = pyplot.title(\"log(GDP (Billions)) vs Happiness Score\")\n",
    "_ = pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "##### Have to take the exponential of whatever you predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding R^2 for second model\n",
    "rSquare2 = 1 - SSE2[0] / sum((y - y.mean())**2) \n",
    "rSquare2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 for this model is 0.3190. This tells us that 31.9% of the variation in happiness score can be explained by log(GDP). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Model\n",
    "pyplot.plot(df_final[\"GDP Per Capita\"],df_final[\"Happiness Score\"], \"bo\") #Covers several orders of magnitude\n",
    "pyplot.xlabel(\"GDP Per Capita\")\n",
    "pyplot.ylabel(\"Happiness Score\")\n",
    "pyplot.title(\"GDP Per Capita vs Happiness Score\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scattplot for GDP per capita looks to be off by multiple orders of magnitude like the initial scatterplot for the second model. We can take another log() transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Model\n",
    "pyplot.plot(np.log(df_final[\"GDP Per Capita\"]),df_final[\"Happiness Score\"], \"bo\") #Covers several orders of magnitude\n",
    "pyplot.xlabel(\"log(GDP Per Capita)\")\n",
    "pyplot.ylabel(\"Happiness Score\")\n",
    "pyplot.title(\"log(GDP Per Capita) vs Happiness Score\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, log() transformation fixes our data and we're ready to fit a linear model to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = np.log(df_final[\"GDP Per Capita\"])\n",
    "\n",
    "A3 = np.vstack([x3, np.ones(len(x3))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3, SSE3 = np.linalg.lstsq(A3, y, rcond=None)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pyplot.plot(x3, y, 'o', label='Original data')\n",
    "_ = pyplot.plot(x3, model3[0]*x3 + model3[1], 'r', label='Fitted line')\n",
    "_ = pyplot.xlabel(\"log(GDP Per Capita)\")\n",
    "_ = pyplot.ylabel(\"Happiness Score\")\n",
    "_ = pyplot.title(\"log(GDP Per Capita) vs Happiness Score\")\n",
    "_ = pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "##### Have to take the exponential of whatever you predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding R^2 for third model\n",
    "rSquare3 = 1 - SSE3[0] / sum((y - y.mean())**2) \n",
    "rSquare3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 for this model is 0.7306. This tells us that 73.06% of the variation in happiness score can be explained by log(GDP per capita). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth Model\n",
    "pyplot.plot(df_final[\"Financial Freedom\"],df_final[\"Happiness Score\"], \"bo\")\n",
    "pyplot.xlabel(\"Financial Freedom\")\n",
    "pyplot.ylabel(\"Happiness Score\")\n",
    "pyplot.title(\"Financial Freedom vs Happiness Score\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there's a bit of a quadratic trend in the data, so we can take a square transformation for financial freedom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth Model\n",
    "pyplot.plot(df_final[\"Financial Freedom\"]**2,df_final[\"Happiness Score\"], \"bo\")\n",
    "pyplot.xlabel(\"Financial Freedom\")\n",
    "pyplot.ylabel(\"Happiness Score\")\n",
    "pyplot.title(\"Financial Freedom vs Happiness Score\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a bit better. We can fit a linear model using this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = df_final[\"Financial Freedom\"]**2\n",
    "\n",
    "A4 = np.vstack([x4, np.ones(len(x4))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4, SSE4 = np.linalg.lstsq(A4, y, rcond=None)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pyplot.plot(x4, y, 'o', label='Original data')\n",
    "_ = pyplot.plot(x4, model4[0]*x4 + model4[1], 'r', label='Fitted line')\n",
    "_ = pyplot.xlabel(\"Financial Freedom^2\")\n",
    "_ = pyplot.ylabel(\"Happiness Score\")\n",
    "_ = pyplot.title(\"Financial Freedom^2 vs Happiness Score\")\n",
    "_ = pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "##### Have to take the square root of whatever you predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding R^2 for fourth model\n",
    "rSquare4 = 1 - SSE4[0] / sum((y - y.mean())**2) \n",
    "rSquare4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The r^2 for this model is 0.4696. This tells us that 46.96% of the variation in happiness score can be explained by financial freedom^2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple linear regression model \n",
    "X = np.transpose(np.array([np.log(df_final[\"GDP (Billions)\"]), df_final[\"Economic Freedom\"], np.log(df_final[\"GDP Per Capita\"]),(df_final['Financial Freedom'])**2]))\n",
    "reg5 = LinearRegression().fit(X, y)\n",
    "# r^2 for mlr model\n",
    "reg5.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This multiple linear regression model gives an r^2 of 0.7423. This tells us that 74.23% of the variation in happiness score can be explained by financial freedom^2, log(GDP per capita), log(GDP), and economic freedom. We still need to check for multicollinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating VIF for each variable in the mlr\n",
    "\n",
    "X = df_final[['GDP (Billions)', 'Economic Freedom', 'GDP Per Capita', 'Financial Freedom']]\n",
    "X[\"GDP (Billions)\"] = np.log(X[\"GDP (Billions)\"])\n",
    "X[\"GDP Per Capita\"] = np.log(X[\"GDP Per Capita\"])\n",
    "X[\"Financial Freedom\"] = (X[\"Financial Freedom\"])**2\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Economic freedom and financial freedom are extrememly correlated. We need to drop one of these variables from the model. Since economic freedom did not require a transformation and had a better r^2 in its own simple linear regression model, we will drop financial freedom^2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(np.array([np.log(df_final[\"GDP (Billions)\"]), df_final[\"Economic Freedom\"], np.log(df_final[\"GDP Per Capita\"])]))\n",
    "reg6 = LinearRegression().fit(X, y)\n",
    "# r^2 for mlr model\n",
    "reg6.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating VIF for each variable in the mlr\n",
    "\n",
    "X = df_final[['GDP (Billions)', 'Economic Freedom', 'GDP Per Capita']]\n",
    "X[\"GDP (Billions)\"] = np.log(X[\"GDP (Billions)\"])\n",
    "X[\"GDP Per Capita\"] = np.log(X[\"GDP Per Capita\"])\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we obtain high VIFs from our model. We could try removing GDP per capita since it has the highest VIF and see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(np.array([np.log(df_final[\"GDP (Billions)\"]), df_final[\"Economic Freedom\"]]))\n",
    "reg7 = LinearRegression().fit(X, y)\n",
    "# r^2 for mlr model\n",
    "reg7.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating VIF for each variable in the mlr\n",
    "\n",
    "X = df_final[['GDP (Billions)', 'Economic Freedom']]\n",
    "X[\"GDP (Billions)\"] = np.log(X[\"GDP (Billions)\"])\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we obtain high VIFs. The best predictors of happiness score all seem to have multicollinearity so we will resort back to a simple linear regression model. The best model that we found above was the model which used the log() of GDP per capita. Overall, the best predictor of happiness that we found was log(GDP per capita). We had to take a log() transformation because GDP per capita differed by many orders of magnitude over the range of happiness score. The coefficient predicton for this model was 0.634. This tells us that for a 1 unit increase in log(GDP per capita) in a country, the happiness score of that country is predicted to increase by 0.634. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(data_folder / \"countries.geo.json\", \"r\")\n",
    "countries_geojson = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load in the .geo.json file which will be used to create the map. We will be plotting happiness score on each country in the happiness dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_from_geojson = []\n",
    "for item in countries_geojson[\"features\"]:\n",
    "    countries_from_geojson.append(item.get(\"properties\", {}).get(\"name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a list of countries in the .geo.json file. This way we're able to compare which countries are in the .json and which are in the happiness csv and see if any country names need to be changed or removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(countries_from_geojson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which countries are not in geojson\n",
    "for _item in happinessDF['Country or region'].unique():\n",
    "    if _item not in countries_from_geojson:\n",
    "        print(_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "United States, Trinidad & Tobago, North Macedonia, and Congo (Kinshasa) need to be renamed to match what is in the happinessDF. Sinapore, Bahrain, Mauritus, Serbia, Hong Kong, Palestinian Territories, Congo (Brazzaville), and Tanzania need to be removed since they are not in the happinessDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happinessDF1 = happinessDF.replace({\"United States\": \"United States of America\", \"Trinidad & Tobago\": \"Trinidad and Tobago\", \"North Macedonia\": \"Macedonia\", \n",
    "\"Congo (Kinshasa)\": \"Democratic Republic of the Congo\"})\n",
    "\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Singapore']\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Bahrain']\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Mauritius']\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Serbia']\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Hong Kong']\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Palestinian Territories']\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Congo (Brazzaville)']\n",
    "happinessDF1 = happinessDF1[happinessDF1['Country or region'] != 'Tanzania']\n",
    "\n",
    "country_df = happinessDF1[['Country or region', 'Score']]\n",
    "country_df = country_df.rename(columns={\"Country or region\": \"Name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we change the names of countries to match what they hare in the happinessDF. We also remove countries that we don't have shape properties for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in countries_geojson[\"features\"]:\n",
    "    key = item.get(\"properties\", {}).get(\"name\")\n",
    "    score = re.findall(r'(\\d\\.\\d+)|$', str(country_df[country_df['Name']==key]['Score']))[0]\n",
    "    content = f\"Name: {key} | Happiness Score: {str(score)}\"\n",
    "    item['properties']['content'] = content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating what will be displayed when the user hovers over a country in the map. We will display the country name and happiness score for the countries that have a happiness score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = folium.Map(\n",
    "    location=[0,0],\n",
    "    zoom_start=3\n",
    ")\n",
    "\n",
    "tiles = ['stamenwatercolor', 'cartodbpositron', 'openstreetmap', 'stamenterrain']\n",
    "for tile in tiles:\n",
    "    folium.TileLayer(tile).add_to(df_map)\n",
    "\n",
    "\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=countries_geojson,\n",
    "    key_on='feature.properties.name',\n",
    "    data=country_df, \n",
    "    columns=['Name', 'Score'], \n",
    "    fill_color='PuBuGn',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    highlight=True,\n",
    "    legend_name=\"Happiness Score\"\n",
    ").add_to(df_map)\n",
    "\n",
    "folium.LayerControl().add_to(df_map)\n",
    "\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['content'], labels=False,\n",
    "                                   style=('background-color: grey; color: white;'))\n",
    ")\n",
    "\n",
    "df_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code we use to create the choropleth map for happiness score by country. A legend for what the shading of each country means and what happiness score this corresponds to can be viewed in the top right. The dark grey countries are those which don't have a happiness score. This map gives us a good indication of which countries and overall regions are the happiest. By the legend we can see that the happiest countries are those that are filled with a darker green. Going by this, it seems like the overall happiest part of the work is Scandinavia as Norway, Sweden, Denmark, and Finland are all dark green. Overall, Europe is also a very happy place, especially central Europe which include countries like Switzerland, Austria, Germany, Holland, Belgium, and the Czech Republic. Oceania which includes Austrailia and New Zealand also seems to be a very happy region overall. The final region that seems to be the most happy is most of North and Central America. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
